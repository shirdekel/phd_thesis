## General Discussion

Most of the hypotheses were supported. This chapter found that, in the capital
allocation context, people's decisions are influenced by anecdotes, even when
aggregated data are available. There were three novel findings: (a) the
anecdotal bias effect was only seen when participants considered the anecdote
sufficiently relevant to the target project, (b) participants integrated
statistics into their decisions, and (c) these effects were found in both
negative and positive anecdotes. Further, people did not consider verbal sample
distribution information, which could have helped to inform their decisions.
This is surprising since other work showed that generalisations are sensitive to
sampling [@carvalho2021].

The first novel finding from these experiments is that participants' use of
anecdotal evidence depended on the anecdote's similarity. Specifically, if the
anecdote appeared relevant, participants used it in their decisions. However,
when it appeared irrelevant, participants almost entirely relied on statistics.
The findings for high anecdote similarity are largely congruent with findings
from other work investigating anecdotal bias in business decision-making. As in
@wainberg2013 and @wainberg2018, this chapter found that people allocated less
capital to a project when presented with statistical evidence and a similar but
contradictory anecdote than when they were presented with statistics alone.

It appears that participants distinguished between the low- and high-similarity
anecdotes based on the structure of the anecdote. The low similarity condition
always included the same project type as the high similarity condition for all
domains. For instance, in one variation, both the high- and low-similarity
anecdotes involved oil well projects. However, the high-similarity anecdotes
also matched the target project in a number of specific features. This means
that participants were sensitive to the specific information in the anecdote
description and analysis and did not simply use the project type for their
inferences. Further, participants' answers to the follow-up questions indicated
that they did not consider that the anecdote was necessarily relevant to other
projects from the same industry. In other words, participants did not appear to
carelessly use anecdotal evidence in their decisions; rather, they carefully
considered the anecdote according to its particular causal structure.

The second novel finding from these experiments is that participants who were
shown the anecdote with statistics did not completely disregard the statistical
measures. @wainberg2013 found a complete anecdotal bias effect because results
for the anecdote only and anecdote & statistics conditions were equivalent,
meaning that the presented statistics had a negligible effect on participants'
decisions. In contrast, the experiments discussed in this chapter showed a
partial anecdotal bias effect, seen as a difference in allocations between the
anecdote only and anecdote & statistics conditions. It appears that participants
integrated both anecdotal and statistical information. This suggests that
people's evaluation of evidence may be more sensitive than previously thought.

The discrepancy between these results and those in @wainberg2013 could be a
result of the sampled population. Since @freling2020 found that anecdotes had a
stronger effect when decisions were more personally relevant; thus, the managers
recruited for the @wainberg2013 study may have simply been more personally
invested in the task compared with the laypeople recruited for the experiments
presented in this chapter. Similarly, @yang2015 found that anxiety increases
anecdotal bias when making risky decisions. However, the discrepancy may also be
attributable to the difference in the anecdote & statistics condition between
the @wainberg2013 study and the present work. Specifically, the statistics
presented in the anecdote & statistics condition in @wainberg2013 were not the
same as those shown in the same study's statistics only condition, unlike in
both the present experiments and @wainberg2018. Instead, it was the anecdote &
enhanced statistics condition that contained the same statistics as in the
statistics only condition. This suggests that people only integrate statistics
when they are sufficiently clear and no further interpretation is required.

The third novel finding from these experiments is that anecdotal bias was found
for both negative and positive anecdotes. Most previous studies have included
negative anecdotes (i.e. those with negative consequences) such as a medication
that fails to reduce symptoms. However, there is little work in the literature
involving positive anecdotes (those with positive consequences). @jaramillo2019
found an asymmetry in the anecdote effect---the effect of the anecdote was
stronger when the medication failed to improve symptoms (negative anecdote)
compared with when it did improve symptoms (positive anecdote). The present
experiments found a more symmetrical effect---the effects of both anecdotal bias
and statistics were found for both negative and positive anecdotes.

The difference between the findings of this chapter and those of @jaramillo2019
may be attributable to the latter's negative anecdote representing a persistence
in a negative shift from the status quo (i.e. good health). In the business
domain, both positive and negative anecdotes represent shifts from the status
quo (a company's financial position). Nevertheless, it was surprising to find no
asymmetry given the predictions of prospect theory. Loss aversion suggests that
participants will avoid projects that are similar to negative anecdotes more
than they will choose those similar to positive anecdotes. However, each choice
was associated with conflicting statistical information, so this may have
cancelled out the change from the reference point. Future research should use
more realistic incentives to investigate this effect further. Doing so will also
increase the ecological validity of the findings.

### Theoretical Implications

The findings presented in this chapter add to the current understanding of the
way in which people use different types of evidence in their decision-making.
Previous works have mostly investigated the relative influence of statistics and
anecdotes by comparing anecdotal with statistical conditions. The current work
shows that comparing a joint anecdote & statistics condition with both an
anecdote only and statistics only condition enables a more specific
investigation of participants' anecdotal bias. The influence of anecdotes can be
seen in the comparison of the statistics only and the anecdote & statistics
conditions, while the effect of statistics can be seen in the comparison of the
anecdote & statistics condition and the anecdote only condition. These two
effects enable the determination of the independent influences of anecdote &
statistics. Use of such a design in future research may help to further the
understanding of conditions under which these types of evidence are used.

Some of the anecdotal bias literature is based on the assumption that using
anecdotal evidence over statistical evidence is necessarily irrational. This is
likely to have arisen from examples in the medical domain in which such
decisions are indeed irrational (e.g., believing that vaccines cause certain
disorders, despite the available evidence). In such cases, people over-rely on
anecdotes and should be relying more on aggregated data. However, a case could
be made for the rational use of an anecdote based on its similarity to the
target problem. For instance, there are times when an anecdote is so similar to
the target situation (e.g., the identical twin example discussed in
SectionÂ \@ref(effect-of-similarity)) that it would be unwise not to consider it.
That is, the use of anecdote should depend on both (a) the extent of underlying
structural similarity to the target problem and (b) the distribution of this
similarity across the pool from which the anecdote was sampled. People should
use anecdotes if their casual structures are significantly more relevant
compared with other cases in the available data.

However, similarity can also be misleading. For instance, if a case appears
highly similar but differs in terms of a key hidden dimension that is the real
causal mechanism, then using the anecdote may be the wrong thing to do. What
appears to be important is being sensitive to relational rather than surface
similarity. Future research should investigate how varying participants'
assumptions about sampling from a data set of anecdotes influences their
anecdotal bias. Such assumptions can include the size of the sample, the shape
of the distribution, and where in the distribution the anecdote came from. Prior
work found that people are sensitive to distributional properties when
generalizing [@carvalho2021], but it is not clear if this will replicate with
descriptive cues such as in the experiments in this chapter.
 
### Practical Implications

The current work contributes to managerial decision-making by providing insights
into how managers make better decisions when using case studies and statistical
information. Managers of large companies are often in a difficult position; they
have incomplete information and are in an uncertain environment. Despite this,
different biases and responses to those biases may be anticipated for different
levels of uncertainty. For instance, a manager may be presented with both a
convincing case study that suggests a certain course of action as well as
aggregated data. The manager needs to be able to weigh the evidence accordingly.

The work in this chapter suggests that there are three elements to consider: (a)
the quality of aggregated data (determined by factors such as sample size), (b)
the relative similarity of the cases in the data pool to the target situation,
and (c) the similarity of the anecdote to the target problem. For instance, an
anecdote that is similar to the target situation in terms of relevance and is
significantly more similar than other cases in the data set should carry more
weight than an anecdote that comes from a pool of cases that are all equally
similar to the target problem. @lovallo2012 found that similarity judgements
increase prediction accuracy beyond a simple regression model. Taking into
account a project's relative similarity to other cases is likely to further
increase predictive validity.

When aggregated data are not available, however, managers should rely more on
anecdotes that have greater similarities in terms of causal structure. That is,
they should be wary of merely using surface similarities to make inferences and
instead consider the underlying relational structures. The present data suggest
that laypeople can do this to some extent, with participants not being
completely swayed by the mere similarity of type of business project. However,
future research should investigate this further to better understand the
boundaries of people's analogical reasoning in capital allocation decisions.

\newpage

\printbibliography[segment=\therefsegment,heading=subbibintoc]
